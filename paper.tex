\documentclass[
  a4paper,
  abstracton,
  emulatestandardclasses,
]{scrartcl}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{bm}
\usepackage{siunitx}
\usepackage{authblk}
\usepackage{physics}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{parskip}
\usepackage{biblatex}
\usepackage{enumerate}
\usepackage{hyperref}

\title{MR to CT Translation with CNNs and GANs}
\author[1]{Bodo Kaiser}
\author[2]{Shadi Albarqouni}
\affil[1]{Ludwig-Maximilians-Universit채t M체nchen}
\affil[2]{Technische Universit채t M체nchen}

\addbibresource{literature.bib}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

Modern cancer treatment incorporates computer tomography (CT) and magnetic
resonance tomography (MR) as the main imaging modalities. Radiation therapy
(RT) and CT are based on the interaction of high energy photons (x-rays) with
biological tissue, therefore so called image guided planning based on the
patients CT scan is used to estimate the patients specific radiation treatment
planning. Even though x-rays used for imaging are of a lower energy band
as x-rays used for cancer treatment, it has been shown that they still possess
a risk of developing new cancer inside the patient \cite{Martin06}.
MR on the other hand takes advantage of the magnetic properties of hydrogen
and is not associated with any health risks \cite{Hartwig09}. Furthermore MR
provides a much higher soft tissue contrast which is useful for cancer
classification. Although MR and CT differ significant in the applied
physics the high entropy in MR data suggests the existence of a one
directional mapping from MR to CT space whereby the acquisition of CT would
become obsolete. Beside the stated health benefits for the patients such an
approach would reduce expanses and also would free CT resources for
emergency cases where the fast acquisition of CT is used to locate internal
bleedings.

\section{Related Work}

Since the early days of CTs health manufacturer were attempted to reduce
radiation exposure in CT scans by using i.e. more sensible detection
electronics and more sophisticated scanning sequences. Through the growing
availability of computing power we also find evermore computer vision
techniques being utilized, for example to enhance the image quality of
low-dose CTs \cite{Xu12}. Altough these efforts have lead to an
impressive and steady evolution of CT apparatus, they still require the
patient to be irradiated.

First approaches which dispense with radiation exposure, relay on the
atlas based transformations applied to MR to predict CT \cite{Hofmann08}.
Further improvements included i.e. random forests \cite{Andreasen13}.
It has been shown that CT prediction can in fact replace CT for treatment
planning \cite{Andreasen2017}.

In computer science we have seen an incredible progress with
deep learning techniques in a variety of areas including natural language
processing and computer vision \cite{LeCun15}. Recent efforts with generative
adversarial networks (GANs) \cite{Goodfellow14} seem to be a promising
path towards the challenge of finding appropriate target functions to optimize
through the use of game theory. Successful applications in computer vision
in which GANs proved significant improvements over the former state of art
include the task of image to image translation \cite{Isola16} but also the
generalization of three dimensional structures inside the so called latent
space \cite{ZXFT16}.

This in mind the medical computer vision community rapidly adapted
GANs for their own specific tasks which in comparison to computer
vision typical involve volumetric single channel images with high bit depth.
Bearing the challenge of CT from MR prediction the expectations towards GANs
have been met showing overall better results compared to the previous
approach \cite{Nie16}. Additionally the full potential of GANs have not
been exhausted yet as it also has been shown that GANs are capable of
being trained with unregistered modalities \cite{Wolterink17}.

Beside the enourmous breakthroughs made in medical computer vision we still
see a shortage in a reproducable comparison of recent methods with publicly
available data. Not to mention the open questions with regard to best
practices in choosing good GAN model parameters for the task of CT prediction
which we hope to address in the subsequent sections.

\section{Method}

In the consecutive parts we discuss the parameters relevant for the conducted
experiments. This includes decisions we made for the setup as a whole
(dataset, pre processing) but also detail decisions regarding for example
the implementation of a specific model. The source code based on the
Tensorflow framework \cite{tensorflow15} will be made available through
GitHub after acceptance.

\subsection{Data}

We used the publicly available dataset from RIRE \cite{RIRE} which contains
contains multi modality data of about 19 patients from which a subset
of 17 patients have a complete pair of T1 weighted MR and CT volume.

We were able to co-register the modalities using \cite{SPM12} and the
highest interpolation order. In the same step we also resliced the volumes
to have a homogenous voxel size as the RIRE dataset has only a low resolution
in the sagittal plane.

Finally we used \cite{Nibabel} to load the aligned volumes and convert them
into Tensorflow's tfrecord format and split them into a validation set of
4 and a training set of 13 patients. Inside the tensorflow input pipeline
we normalized the value range of each volume to $[0,1]$. For two dimensional
models we padded the horizontal slices to $384\times384$. For three
dimensional models we used $260\times340\times360$ (Depth x Height x Width).

\subsection{Network}

As generative adversarial networks we decided to use pix2pix \cite{Isola16}
as it has already shown great results in the task of color image to image
translation and context-aware 3d synthesis \cite{Nie16} which uses a simpler
generator but accounts for 3d structures.

As convolutional encoder-decoder network we chose u-net \cite{Ronneberger15}
as it was able to compete with much larger models in the task of semantic
segmentation \cite{Badrinarayanan15}. Further our implementation of pix2pix
uses u-net as generator network, hence we are able to evaluate the impact
of the adversarial min-max approach.

Eventually we want to evaluate a new network and training approach novel to
medical computer vision \cite{Karras17}.

\subsubsection{U-Net}


\subsubsection{Pix2Pix}

\subsubsection{3D Synthesis}

\subsection{Losses}

\subsubsection{Distance Losses}

As norm losses we refer to the mean absolute error ($L1$ loss) and the
mean squared error ($L2$ loss).

\subsubsection{Gradient Losses}

The gradient (difference) loss is used in the framework of context-aware
3d synthesis \cite{Nie16} in addition to the norm loss.

\subsubsection{Signal Losses}

From signal processing PSNR, SSE...

\subsubsection{Adversarial Loss}

Least-squared adversarial loss, standard adversarial loss. BEGAN loss ?


\subsection{Augmentation}

\subsubsection{Random Crop}
\subsubsection{Rotation}
\subsubsection{Contast Adjustment}

\section{Results}

\subsection{Losses}

\subsection{Augmentation}

\section{Conclusion}

\printbibliography{}

\end{document}
