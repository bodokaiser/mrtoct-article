\section{Experiments}

We had difficulties with the implementation of the patch aggregation required
for the implementation of the context-aware 3D synthesis. Though patch
aggregation worked in general, it occupied more computational resources than
the actual training. Unfortunatly we were not able to find a workaround or to
allocate more computation quota. Therefor we did not perform more than one
iteration of the auto-context model, which prevented a fair comparison.
However, we encourage everyone to test our implementation themselves.
As a consequence we only conducted experiments with the u-net generator and
the pixtopix \gls{gan}.

\subsection{Distance Losses}

One experimental parameter of interest was the performance impact of the
different loss functions. We first optimized the loss function used when
only training the u-net. Let $X,Y\in{[0,1]}^N$ be output and target vectors,
then we define the \gls{mae} to be
\begin{equation}
  \mae\left(X,Y\right)
  =
  \frac{1}{N}\sum_{i=1}^N
  \abs{X_i-Y_i}
  \label{eq:mae}.
\end{equation}
The \gls{mse} we define via
\begin{equation}
  \mse\left(X,Y\right)
  =
  \frac{1}{N}\sum_{i=1}^N
  {\left(X_i-Y_j\right)}^2
  \label{eq:mse}.
\end{equation}
Finally the \gls{gdl} disclosed in Ref.~\cite{Nie16} is defined as
\begin{equation}
  \gdl\left(X,Y\right)
  =
  \mse\left(\grad X,\grad Y\right)
  \label{eq:gdl},
\end{equation}
wherein $\grad$ is the spatial gradient. We approximate the $i$th element
of the spatial gradient through
\begin{equation}
  \grad X_i
  \approx
  \begin{cases}
    X_i-X_{i+1}\qc\text{if }, $1<i<N$\\
    0\qc\text{otherwise}
  \end{cases}
  \label{eq:grad}.
\end{equation}
The loss terms can of course be combined
\begin{equation}
  \lambda_\text{MAE}\mae\left(X,Y\right)
  +
  \lambda_\text{MSE}\mse\left(X,Y\right)
  +
  \lambda_\text{GDL}\gdl\left(X,Y\right),
\end{equation}
wherein the $\lambda$ denotes the weight of the respective loss term.

\begin{table}[h]
  \centering
  \begin{tabular}{ccc}
    \toprule
    Dataset & Subject & Shape \\
    \midrule
    Training & \num{1} & \num{161x320x250x1} \\
    Training & \num{2} & \num{149x328x250x1} \\
    Training & \num{3} & \num{112x303x281x1} \\
    Training & \num{4} & \num{155x291x259x1} \\
    Training & \num{5} & \num{143x307x284x1} \\
    Training & \num{6} & \num{149x278x267x1} \\
    Training & \num{7} & \num{200x289x268x1} \\
    Training & \num{8} & \num{218x282x238x1} \\
    Training & \num{9} & \num{191x322x252x1} \\
    Training & \num{10} & \num{200x303x243x1} \\
    Training & \num{11} & \num{181x317x239x1} \\
    Training & \num{12} & \num{186x310x248x1} \\
    Training & \num{13} & \num{112x313x238x1} \\
    Validation & \num{1} & \num{112x298x227x1} \\
    Validation & \num{2} & \num{223x328x282x1} \\
    Validation & \num{3} & \num{223x307x276x1} \\
    Validation & \num{4} & \num{204x329x262x1} \\
    \bottomrule
  \end{tabular}
  \caption{Training and validation dataset volumes used in this section. The
    dimensions of the shape correspond to depth, height and width.
  }\label{tab:distance:dataset}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{cccccc}
    \toprule
    & &
    \multicolumn{2}{c}{$\lambda_\text{mae}=1,\lambda_\text{gdl}=0$} &
    \multicolumn{2}{c}{$\lambda_\text{mae}=1,\lambda_\text{gdl}=\num{1e-7}$} \\
    Image Slices & Batch Size & Steps & Epochs & Steps & Epochs \\
    \midrule
    \num{2157} & \num{16} & \num{20542} & \num{152} & \num{19388} & \num{143} \\
    \bottomrule
  \end{tabular}
  \caption{Training parameters used for the distance metrics experiments.
  }\label{tab:distance:params}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{ccccc}
    \toprule
    $\lambda_\text{mae}$ &
    $\lambda_\text{gdl}$ &
    \acrshort{mae} &
    \acrshort{mse} &
    \acrshort{psnr} \\
    \midrule
    \num{1} & \num{0} & \num{31.58} & \num{6577} & \num{59.5} \\
    \num{1} & \num{1e-7} & \num{37.15} & \num{7945} & \num{58.1} \\
    \bottomrule
  \end{tabular}
  \caption{Distance metrics for the u-net model trained with different loss
    functions, evaluated on the training dataset.
  }\label{tab:distance:training}
\end{table}
\begin{table}[h]
  \centering
  \begin{tabular}{ccccc}
    \toprule
    $\lambda_\text{mae}$ &
    $\lambda_\text{gdl}$ &
    \acrshort{mae} &
    \acrshort{mse} &
    \acrshort{psnr} \\
    \midrule
    \num{1} & \num{0} & \num{123.6} & \num{70846} & \num{47.93} \\
    \num{1} & \num{1e-7} & \num{129.0} & \num{72704} & \num{47.90} \\
    \bottomrule
  \end{tabular}
  \caption{Distance metrics for the u-net model trained with different loss
    functions, evaluated on the validation dataset.
  }\label{tab:distance:validation}
\end{table}
\begin{figure}[h]
  \centering
  \begin{adjustbox}{width=\linewidth}
    \inputpgf{figure}{distance-losses-training.pgf}
  \end{adjustbox}
  \caption{Transverse views for the u-net model trained with different
    loss functions, evaluated on the training dataset.
  }\label{fig:distance:training}
\end{figure}
\begin{figure}[h]
  \centering
  \begin{adjustbox}{width=\linewidth}
    \inputpgf{figure}{distance-losses-validation.pgf}
  \end{adjustbox}
  \caption{Transverse views for the u-net model trained with different
    loss functions, evaluated on the validation dataset.
  }\label{fig:distance:validation}
\end{figure}

\subsection{Adversarial Losses}

% LSGAN, MinMaxAdvLoss

\subsection{Gradient Boost}

% Boost brain matter tissue
